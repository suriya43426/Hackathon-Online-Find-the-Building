{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import accelerate\n","accelerate.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install -U accelerate==0.18.0"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-06-03T14:01:49.318961Z","iopub.status.busy":"2023-06-03T14:01:49.318477Z","iopub.status.idle":"2023-06-03T14:01:50.669929Z","shell.execute_reply":"2023-06-03T14:01:50.666807Z","shell.execute_reply.started":"2023-06-03T14:01:49.318932Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","import sys\n","\n","from sklearn.model_selection import StratifiedKFold\n","\n","import timm\n","from timm.models import create_model,build_model_with_cfg\n","from timm.optim import create_optimizer_v2\n","from timm.scheduler import create_scheduler_v2\n","from timm.loss import LabelSmoothingCrossEntropy,BinaryCrossEntropy,JsdCrossEntropy\n","from timm.utils import AverageMeter,ModelEmaV2\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","\n","from accelerate import Accelerator\n","from accelerate.utils import set_seed\n","\n","from tqdm import tqdm\n","from IPython.display import clear_output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T14:01:50.672359Z","iopub.status.busy":"2023-06-03T14:01:50.671808Z","iopub.status.idle":"2023-06-03T14:01:51.967152Z","shell.execute_reply":"2023-06-03T14:01:51.966206Z","shell.execute_reply.started":"2023-06-03T14:01:50.672324Z"},"trusted":true},"outputs":[],"source":["import evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T14:01:51.969620Z","iopub.status.busy":"2023-06-03T14:01:51.968701Z","iopub.status.idle":"2023-06-03T14:01:54.641592Z","shell.execute_reply":"2023-06-03T14:01:54.640704Z","shell.execute_reply.started":"2023-06-03T14:01:51.969584Z"},"trusted":true},"outputs":[],"source":["import wandb\n","wandb.login(key=\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T14:01:54.645663Z","iopub.status.busy":"2023-06-03T14:01:54.645021Z","iopub.status.idle":"2023-06-03T14:01:54.657210Z","shell.execute_reply":"2023-06-03T14:01:54.656259Z","shell.execute_reply.started":"2023-06-03T14:01:54.645635Z"},"trusted":true},"outputs":[],"source":["timm.list_models('*convn*',pretrained=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T14:01:54.661154Z","iopub.status.busy":"2023-06-03T14:01:54.658520Z","iopub.status.idle":"2023-06-03T14:02:02.395791Z","shell.execute_reply":"2023-06-03T14:02:02.394763Z","shell.execute_reply.started":"2023-06-03T14:01:54.661127Z"},"trusted":true},"outputs":[],"source":["ckp = 'convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384'\n","model = create_model(ckp,in_chans=3, num_classes=2, pretrained=True)\n","data_config = timm.data.resolve_model_data_config(model)\n","transform = timm.data.create_transform(**data_config, is_training=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T14:02:02.397471Z","iopub.status.busy":"2023-06-03T14:02:02.397116Z","iopub.status.idle":"2023-06-03T14:02:02.405560Z","shell.execute_reply":"2023-06-03T14:02:02.404520Z","shell.execute_reply.started":"2023-06-03T14:02:02.397437Z"},"trusted":true},"outputs":[],"source":["class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, df, transform):\n","        self.df = df\n","        self.transform = transform\n","        \n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        image = Image.open(\"/kaggle/input/hackathon-online-find-the-buildings/train/train/\"+row[\"file\"])\n","        image = image.convert(\"RGB\")\n","        image = self.transform(image)\n","        label = row['label']\n","        return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T14:02:02.408274Z","iopub.status.busy":"2023-06-03T14:02:02.407522Z","iopub.status.idle":"2023-06-03T14:02:02.417549Z","shell.execute_reply":"2023-06-03T14:02:02.416307Z","shell.execute_reply.started":"2023-06-03T14:02:02.408219Z"},"trusted":true},"outputs":[],"source":["def get_dataloaders(datasets,batch_size: int = 64):\n","    train_size = int(0.9 * len(datasets))\n","    test_size = len(datasets) - train_size\n","    train_dataset, test_dataset = torch.utils.data.random_split(\n","        datasets, [train_size, test_size])\n","\n","    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n","                                                    pin_memory=True,\n","                                                    shuffle=True,\n","                                                    num_workers=2)\n","    eval_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size*2,\n","                                                    pin_memory=True,\n","                                                    shuffle=False,\n","                                                    num_workers=2)\n","    return train_dataloader, eval_dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T14:02:02.419645Z","iopub.status.busy":"2023-06-03T14:02:02.419228Z","iopub.status.idle":"2023-06-03T14:02:02.435754Z","shell.execute_reply":"2023-06-03T14:02:02.434740Z","shell.execute_reply.started":"2023-06-03T14:02:02.419606Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(\"/kaggle/input/hackathon-online-find-the-buildings/train.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T14:02:02.437819Z","iopub.status.busy":"2023-06-03T14:02:02.437424Z","iopub.status.idle":"2023-06-03T14:02:02.462227Z","shell.execute_reply":"2023-06-03T14:02:02.461046Z","shell.execute_reply.started":"2023-06-03T14:02:02.437784Z"},"trusted":true},"outputs":[],"source":["def training_function(model,df):\n","    set_seed(43)\n","    num_epochs=100\n","    lr=(5e-6)\n","    batch_size = 8\n","    mixed_precision=\"fp16\"\n","    accelerator = Accelerator(mixed_precision=mixed_precision,\n","                              gradient_accumulation_steps=1,\n","                              log_with=\"wandb\")\n","    \n","    optimizer = create_optimizer_v2(\n","        model, opt=\"adamw\", lr=lr, weight_decay=(1e-2))\n","    scheduler = timm.scheduler.CosineLRScheduler(optimizer, t_initial=2)\n","    criterion = LabelSmoothingCrossEntropy(smoothing=0.1)\n","    accuracy = evaluate.load(\"accuracy\")\n","    \n","    dataset = Dataset(df,transform)\n","    train_dataloader, eval_dataloader = get_dataloaders(dataset,batch_size)\n","    \n","    model, optimizer, train_dataloader, eval_dataloader,scheduler = accelerator.prepare(\n","    model, optimizer, train_dataloader, eval_dataloader,scheduler)\n","    best_score = -1.0\n","    accelerator.init_trackers(\"binary classification\")\n","    \n","    for epoch in range(num_epochs):\n","        model.train()\n","        \n","        num_steps_per_epoch = len(train_dataloader)\n","        num_updates = epoch * num_steps_per_epoch\n","        \n","        train_meters = {\n","            'loss': AverageMeter(),\n","            'acc': AverageMeter(),\n","        }\n","        \n","        if accelerator.is_local_main_process:\n","            train_bar = tqdm(total=len(train_dataloader))\n","\n","        for batch in train_dataloader:\n","            clear_output()\n","            with accelerator.accumulate(model):\n","                x, y = batch\n","                out = model(x)\n","                with accelerator.autocast():\n","                    loss = criterion(out, y)\n","                _,pred = out.max(1)\n","\n","                accelerator.backward(loss)\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","                scheduler.step_update(num_updates=num_updates)\n","\n","            predictions, references = accelerator.gather_for_metrics((pred,y))\n","\n","            acc = accuracy.compute(predictions=predictions, references=references)[\"accuracy\"]\n","\n","            train_meters['loss'].update(loss, n=x.size(0))\n","            train_meters['acc'].update(acc, n=x.size(0))\n","                \n","                \n","            if accelerator.is_local_main_process:\n","                train_bar.update(1)\n","                train_bar.set_description(\n","                        f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f} , Acc: {acc:.4f}\")\n","                    \n","        scheduler.step(epoch + 1)\n","\n","        loss_avg = train_meters['loss'].avg\n","        acc_avg = train_meters['acc'].avg\n","        accelerator.log({\"loss\":loss_avg})\n","        accelerator.log({\"acc\":acc_avg})\n","        if accelerator.is_local_main_process:\n","                train_bar.set_description(\n","                        f\"Epoch {epoch+1}/{num_epochs}, Training Loss Avg: {loss_avg:.4f} , Acc Avg: {acc_avg:.4f}\")\n","        model.eval()\n","        val_meters = {\n","            'loss': AverageMeter(),\n","            'acc': AverageMeter(),\n","        }\n","        if accelerator.is_local_main_process:\n","            val_bar = tqdm(total=len(eval_dataloader))\n","\n","        with torch.no_grad():\n","            for batch in eval_dataloader:\n","                clear_output()\n","                x, y = batch\n","                out = model(x)\n","                with accelerator.autocast():\n","                    loss = criterion(out, y)\n","                val_loss = loss.item()\n","                _,pred = out.max(1)\n","\n","                \n","                predictions, references = accelerator.gather_for_metrics((pred,y))\n","                val_acc = accuracy.compute(predictions=predictions, references=references)[\"accuracy\"]\n","\n","                val_meters['loss'].update(val_loss , n=x.size(0))\n","                val_meters['acc'].update(val_acc, n=x.size(0))\n","                if accelerator.is_local_main_process:\n","                    val_bar.update(1)\n","                    val_bar.set_description(\n","                            f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {loss.item():.4f} , Acc: {val_acc:.4f}\")\n","\n","        loss_avg = val_meters['loss'].avg\n","        acc_avg = val_meters['acc'].avg\n","        accelerator.log({\"val_loss\":loss_avg})\n","        accelerator.log({\"val_acc\":acc_avg})\n","        if accelerator.is_local_main_process:\n","            val_bar.set_description(\n","                f\"Epoch {epoch+1}/{num_epochs}, Validation Loss Avg: {loss_avg:.4f} , Acc Avg: {acc_avg:.4f}\")\n","            \n","    \n","        if val_meters['acc'].avg > best_score:\n","                best_score = val_meters['acc'].avg\n","                accelerator.wait_for_everyone()\n","                accelerator.save(accelerator.get_state_dict(model),f\"./{ckp}.pth\")\n","                accelerator.print(f'Save best model epoch:' + str(epoch + 1))\n","        accelerator.free_memory()\n","    accelerator.end_training()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T14:02:02.466492Z","iopub.status.busy":"2023-06-03T14:02:02.465583Z","iopub.status.idle":"2023-06-03T14:18:50.953227Z","shell.execute_reply":"2023-06-03T14:18:50.951780Z","shell.execute_reply.started":"2023-06-03T14:02:02.466455Z"},"trusted":true},"outputs":[],"source":["from accelerate import notebook_launcher\n","notebook_launcher(training_function,(model,df,),num_processes=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = create_model(\"convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384\",\n","                        in_chans=3, num_classes=2,checkpoint_path=\"/kaggle/working/convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384.pth\").to(\"cuda\")\n","data_config = timm.data.resolve_model_data_config(model)\n","transform = timm.data.create_transform(**data_config, is_training=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T14:21:19.358039Z","iopub.status.busy":"2023-06-03T14:21:19.357583Z","iopub.status.idle":"2023-06-03T14:21:19.366607Z","shell.execute_reply":"2023-06-03T14:21:19.364458Z","shell.execute_reply.started":"2023-06-03T14:21:19.358004Z"},"trusted":true},"outputs":[],"source":["class TestDataset(torch.utils.data.Dataset):\n","    def __init__(self, df, transform):\n","        self.df = df\n","        self.transform = transform\n","        \n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        image = Image.open(\"/kaggle/input/hackathon-online-find-the-buildings/test/\"+row['file'])\n","        image = image.convert(\"RGB\")\n","        image = self.transform(image)\n","        return image"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["batch_size = 100\n","testDf = pd.read_csv(\"/kaggle/input/hackathon-online-find-the-buildings/test.csv\")\n","dataset = TestDataset(testDf,transform)\n","dataloader = torch.utils.data.DataLoader(dataset, pin_memory=True,\n","                                                  num_workers=2,batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T14:21:24.295978Z","iopub.status.busy":"2023-06-03T14:21:24.295458Z","iopub.status.idle":"2023-06-03T14:21:24.405729Z","shell.execute_reply":"2023-06-03T14:21:24.404371Z","shell.execute_reply.started":"2023-06-03T14:21:24.295936Z"},"trusted":true},"outputs":[],"source":["import torch.nn.functional as nnf\n","preds = np.array([])\n","probs = np.array([])\n","for batch in tqdm(dataloader):\n","    model.eval()\n","    with torch.no_grad():\n","        output = model(batch.to(\"cuda\"))\n","    prob = nnf.softmax(output, dim=1)\n","    top_p, top_class = prob.topk(1, dim = 1)\n","    preds = np.append(preds, top_class.cpu().numpy())\n","    probs = np.append(probs, top_p.cpu().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["testDf[\"label\"] = preds.astype(\"int\")\n","#testDf[\"probs\"] = probs\n","\n","testDf[\"label\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T14:47:39.305332Z","iopub.status.busy":"2023-06-03T14:47:39.304818Z","iopub.status.idle":"2023-06-03T14:47:39.325869Z","shell.execute_reply":"2023-06-03T14:47:39.324912Z","shell.execute_reply.started":"2023-06-03T14:47:39.305294Z"},"trusted":true},"outputs":[],"source":["testDf.to_csv(\"submit.csv\",index=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
